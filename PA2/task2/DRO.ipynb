{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf4aa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fatim_Sproj\\anaconda3\\envs\\bacp\\lib\\site-packages\\torch\\cuda\\__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import random_split, DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c83b9541",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(r\"C:\\Users\\Fatim_Sproj\\Desktop\\Fatim\\Spring 2025\\Datasets\\pacs_data\\pacs_data\")\n",
    "SOURCE_DOMAINS = [\"art_painting\", \"cartoon\", \"photo\"]\n",
    "TARGET_DOMAIN = \"sketch\"\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "LR = 3e-4\n",
    "EPOCHS = 10\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12881371",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_RATIO = 0.2\n",
    "\n",
    "class PACSDataset(Dataset):\n",
    "    def __init__(self, root, domain, transform=None):\n",
    "        self.dataset = datasets.ImageFolder(root=root/domain, transform=transform)\n",
    "        self.domain = domain\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[idx]\n",
    "        return img, label, self.domain\n",
    "\n",
    "source_train_loaders = {}\n",
    "source_val_loaders = {}\n",
    "\n",
    "for domain in SOURCE_DOMAINS:\n",
    "    full_dataset = PACSDataset(DATA_ROOT, domain, transform=train_transform)\n",
    "    n_total = len(full_dataset)\n",
    "    n_val = int(VAL_RATIO * n_total)\n",
    "    n_train = n_total - n_val\n",
    "    \n",
    "    train_set, val_set = random_split(full_dataset, [n_train, n_val])\n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    \n",
    "    source_train_loaders[domain] = train_loader\n",
    "    source_val_loaders[domain] = val_loader\n",
    "\n",
    "target_dataset = PACSDataset(DATA_ROOT, TARGET_DOMAIN, transform=val_transform)\n",
    "target_loader = DataLoader(target_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfeb9271",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "num_classes = 7\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41e38509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "SAVE_DIR = Path(\"dro_outputs\")\n",
    "SAVE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "\n",
    "def train_group_dro(model, source_loaders, target_loader, optimizer, epochs, device):\n",
    "    domain_names = list(source_loaders.keys())\n",
    "    best_target_acc = 0.0\n",
    "    best_worst_source_acc = 0.0\n",
    "\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        domain_iterators = {d: iter(l) for d, l in source_loaders.items()}\n",
    "        steps = min(len(l) for l in source_loaders.values())\n",
    "        \n",
    "        worst_losses = []\n",
    "        domain_correct = defaultdict(int)\n",
    "        domain_total = defaultdict(int)\n",
    "\n",
    "        for step in range(steps):\n",
    "            optimizer.zero_grad()\n",
    "            losses = {}\n",
    "\n",
    "            for domain in domain_names:\n",
    "                try:\n",
    "                    x, y, _ = next(domain_iterators[domain])\n",
    "                except StopIteration:\n",
    "                    domain_iterators[domain] = iter(source_loaders[domain])\n",
    "                    x, y, _ = next(domain_iterators[domain])\n",
    "\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits = model(x)\n",
    "                loss = F.cross_entropy(logits, y)\n",
    "                losses[domain] = loss\n",
    "\n",
    "                preds = logits.argmax(dim=1)\n",
    "                domain_correct[domain] += (preds == y).sum().item()\n",
    "                domain_total[domain] += y.size(0)\n",
    "\n",
    "            worst_domain = max(losses, key=losses.get)\n",
    "            worst_loss = losses[worst_domain]\n",
    "            worst_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            worst_losses.append(worst_loss.item())\n",
    "\n",
    "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "        avg_worst_loss = np.mean(worst_losses)\n",
    "        print(f\"Average worst-domain loss: {avg_worst_loss:.4f}\")\n",
    "\n",
    "        source_accs = {}\n",
    "        for domain in domain_names:\n",
    "            acc = domain_correct[domain] / domain_total[domain]\n",
    "            source_accs[domain] = acc\n",
    "            print(f\"Source-domain '{domain}' accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "        worst_source_acc = min(source_accs.values())\n",
    "        print(f\"Worst-source-domain accuracy: {worst_source_acc*100:.2f}%\")\n",
    "\n",
    "        target_acc = evaluate(model, target_loader, \"Target Domain\", device)\n",
    "\n",
    "        if target_acc > best_target_acc:\n",
    "            best_target_acc = target_acc\n",
    "            torch.save(model.state_dict(), SAVE_DIR / \"best_model_target.pth\")\n",
    "            print(f\"Saved new best model (target acc = {target_acc*100:.2f}%)\")\n",
    "\n",
    "        if worst_source_acc > best_worst_source_acc:\n",
    "            best_worst_source_acc = worst_source_acc\n",
    "            torch.save(model.state_dict(), SAVE_DIR / \"best_model_worst_source.pth\")\n",
    "            print(f\"Saved new best model (worst-source acc = {worst_source_acc*100:.2f}%)\")\n",
    "\n",
    "        history.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"avg_worst_loss\": avg_worst_loss,\n",
    "            \"source_accs\": {d: float(a) for d, a in source_accs.items()},\n",
    "            \"worst_source_acc\": float(worst_source_acc),\n",
    "            \"target_acc\": float(target_acc)\n",
    "        })\n",
    "\n",
    "    epochs = [h[\"epoch\"] for h in history]\n",
    "    target_accs = [h[\"target_acc\"] for h in history]\n",
    "    worst_accs = [h[\"worst_source_acc\"] for h in history]\n",
    "    losses = [h[\"avg_worst_loss\"] for h in history]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, target_accs, label=\"Target Acc\")\n",
    "    plt.plot(epochs, worst_accs, label=\"Worst Source Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(SAVE_DIR / \"accuracy_plot.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, losses, label=\"Worst Loss\", color=\"orange\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(SAVE_DIR / \"loss_plot.png\")\n",
    "    plt.close()\n",
    "\n",
    "    return best_target_acc, best_worst_source_acc\n",
    "\n",
    "\n",
    "def evaluate(model, loader, name=\"Dataset\", device=\"cuda\"):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, _ in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    acc = correct / total\n",
    "    print(f\"{name} Accuracy: {acc*100:.2f}%\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9bee1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "Average worst-domain loss: 0.7635\n",
      "Source-domain 'art_painting' accuracy: 77.23%\n",
      "Source-domain 'cartoon' accuracy: 75.30%\n",
      "Source-domain 'photo' accuracy: 85.70%\n",
      "Worst-source-domain accuracy: 75.30%\n",
      "Target Domain Accuracy: 55.59%\n",
      "Saved new best model (target acc = 55.59%)\n",
      "Saved new best model (worst-source acc = 75.30%)\n",
      "\n",
      "Epoch 2/10\n",
      "Average worst-domain loss: 0.2981\n",
      "Source-domain 'art_painting' accuracy: 92.56%\n",
      "Source-domain 'cartoon' accuracy: 93.45%\n",
      "Source-domain 'photo' accuracy: 94.76%\n",
      "Worst-source-domain accuracy: 92.56%\n",
      "Target Domain Accuracy: 62.89%\n",
      "Saved new best model (target acc = 62.89%)\n",
      "Saved new best model (worst-source acc = 92.56%)\n",
      "\n",
      "Epoch 3/10\n",
      "Average worst-domain loss: 0.2040\n",
      "Source-domain 'art_painting' accuracy: 94.94%\n",
      "Source-domain 'cartoon' accuracy: 96.13%\n",
      "Source-domain 'photo' accuracy: 96.26%\n",
      "Worst-source-domain accuracy: 94.94%\n",
      "Target Domain Accuracy: 64.88%\n",
      "Saved new best model (target acc = 64.88%)\n",
      "Saved new best model (worst-source acc = 94.94%)\n",
      "\n",
      "Epoch 4/10\n",
      "Average worst-domain loss: 0.1283\n",
      "Source-domain 'art_painting' accuracy: 97.25%\n",
      "Source-domain 'cartoon' accuracy: 97.54%\n",
      "Source-domain 'photo' accuracy: 97.23%\n",
      "Worst-source-domain accuracy: 97.23%\n",
      "Target Domain Accuracy: 66.05%\n",
      "Saved new best model (target acc = 66.05%)\n",
      "Saved new best model (worst-source acc = 97.23%)\n",
      "\n",
      "Epoch 5/10\n",
      "Average worst-domain loss: 0.1078\n",
      "Source-domain 'art_painting' accuracy: 98.51%\n",
      "Source-domain 'cartoon' accuracy: 97.69%\n",
      "Source-domain 'photo' accuracy: 97.75%\n",
      "Worst-source-domain accuracy: 97.69%\n",
      "Target Domain Accuracy: 65.28%\n",
      "Saved new best model (worst-source acc = 97.69%)\n",
      "\n",
      "Epoch 6/10\n",
      "Average worst-domain loss: 0.0843\n",
      "Source-domain 'art_painting' accuracy: 98.66%\n",
      "Source-domain 'cartoon' accuracy: 98.14%\n",
      "Source-domain 'photo' accuracy: 98.50%\n",
      "Worst-source-domain accuracy: 98.14%\n",
      "Target Domain Accuracy: 68.90%\n",
      "Saved new best model (target acc = 68.90%)\n",
      "Saved new best model (worst-source acc = 98.14%)\n",
      "\n",
      "Epoch 7/10\n",
      "Average worst-domain loss: 0.0727\n",
      "Source-domain 'art_painting' accuracy: 98.36%\n",
      "Source-domain 'cartoon' accuracy: 98.66%\n",
      "Source-domain 'photo' accuracy: 99.10%\n",
      "Worst-source-domain accuracy: 98.36%\n",
      "Target Domain Accuracy: 57.44%\n",
      "Saved new best model (worst-source acc = 98.36%)\n",
      "\n",
      "Epoch 8/10\n",
      "Average worst-domain loss: 0.0638\n",
      "Source-domain 'art_painting' accuracy: 99.18%\n",
      "Source-domain 'cartoon' accuracy: 99.48%\n",
      "Source-domain 'photo' accuracy: 98.95%\n",
      "Worst-source-domain accuracy: 98.95%\n",
      "Target Domain Accuracy: 59.68%\n",
      "Saved new best model (worst-source acc = 98.95%)\n",
      "\n",
      "Epoch 9/10\n",
      "Average worst-domain loss: 0.0502\n",
      "Source-domain 'art_painting' accuracy: 99.03%\n",
      "Source-domain 'cartoon' accuracy: 99.33%\n",
      "Source-domain 'photo' accuracy: 99.40%\n",
      "Worst-source-domain accuracy: 99.03%\n",
      "Target Domain Accuracy: 65.49%\n",
      "Saved new best model (worst-source acc = 99.03%)\n",
      "\n",
      "Epoch 10/10\n",
      "Average worst-domain loss: 0.0495\n",
      "Source-domain 'art_painting' accuracy: 99.11%\n",
      "Source-domain 'cartoon' accuracy: 99.33%\n",
      "Source-domain 'photo' accuracy: 99.48%\n",
      "Worst-source-domain accuracy: 99.11%\n",
      "Target Domain Accuracy: 65.05%\n",
      "Saved new best model (worst-source acc = 99.11%)\n"
     ]
    }
   ],
   "source": [
    "best_target_acc, best_worst_source_acc = train_group_dro(\n",
    "    model, source_train_loaders, target_loader, optimizer, EPOCHS, DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47211588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fatim_Sproj\\AppData\\Local\\Temp\\ipykernel_24860\\3697134344.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(best_model_path, map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source art_painting Accuracy: 85.26%\n",
      "Source cartoon Accuracy: 90.38%\n",
      "Source photo Accuracy: 95.21%\n",
      "Target sketch Accuracy: 68.90%\n",
      "\n",
      "Mean source accuracy: 90.28%\n",
      "Mean domain accuracy (incl. target): 84.94%\n",
      "Saved final model to dro_outputs/\n"
     ]
    }
   ],
   "source": [
    "best_model_path = SAVE_DIR / \"best_model_target.pth\"\n",
    "\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "num_classes = 7\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "state_dict = torch.load(best_model_path, map_location=DEVICE)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "domain_results = {}\n",
    "total_acc = 0.0\n",
    "\n",
    "for d, loader in source_val_loaders.items():\n",
    "    acc = evaluate(model, loader, f\"Source {d}\", DEVICE)\n",
    "    domain_results[d] = acc\n",
    "    total_acc += acc\n",
    "\n",
    "t_acc = evaluate(model, target_loader, f\"Target {TARGET_DOMAIN}\", DEVICE)\n",
    "domain_results[TARGET_DOMAIN] = t_acc\n",
    "total_acc += t_acc\n",
    "\n",
    "mean_source_acc = (total_acc - t_acc) / len(source_val_loaders)\n",
    "mean_acc = total_acc / (len(source_val_loaders) + 1)\n",
    "\n",
    "print(f\"\\nMean source accuracy: {mean_source_acc*100:.2f}%\")\n",
    "print(f\"Mean domain accuracy (incl. target): {mean_acc*100:.2f}%\")\n",
    "\n",
    "torch.save(model, SAVE_DIR / \"final_model_full.pth\")\n",
    "print(\"Saved final model to dro_outputs/\")\n",
    "\n",
    "domains = list(domain_results.keys())\n",
    "accuracies = [domain_results[d] * 100 for d in domains]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(domains, accuracies, color='lightcoral', edgecolor='black', linewidth=1.2)\n",
    "plt.ylabel(\"Accuracy (%)\", fontsize=12)\n",
    "plt.title(\"Per-Domain Accuracy (DRO Final Model)\", fontsize=13, pad=10)\n",
    "plt.xticks(rotation=0, ha='center', fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_DIR / \"domain_accuracy_bar.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bacp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
